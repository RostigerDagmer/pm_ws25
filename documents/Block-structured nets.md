experiments/simulate/structured_net.py
experiments/simulate/model.py

---
### StructuredNet

Is essentially just a tuple of (PN, im, fm) with a label/name attached.
**PN** is a Petrinet representing the semantics of the workflow.
**im** the _initial_ marking(s)
**fm** the _final_ marking(s)

##### DSL/Algebra

Defines algebraic operators congruent to the operators of the Process Tree "Language".

	'>>': Sequence  => A >> B reads as: "A preceeds B"
	'&':  Parallel  => A & B  reads as "A and B are concurrent"
	'^':  Choice    => A ^ B  reads as "Either A or B runs"
	'@':  loop      => A @ B  reads as "A loops with exit B"

In the block structured Workflownet representation they represent the analogous Process Tree operators **exactly**.

If we only consider blocks as valid atoms to be composed, encode them by their size, then any Workflownet structure can be generated by some string:
_note: are required to implement n-ary ops to actually achieve this?_

`(n_l <op> n_r)*` where `n_l, n_r` $\in$ $\mathcal{N}_0^+$

e.g.:
`(10 & ((4 @ 0) ^ (6 ^ (2 & 3)))) >> 2`

==Why this **could** be useful==:
It has been shown that simply the exposure to random but structured complexity seems to have a positive effect on ANNs ([[https://arxiv.org/pdf/2410.02536]]).
The hypothesis is that any data generated by **some** rule can create circuitry under the optimization process that may or may not be useful. The usefulness of **any** circuit/rule is not necessarily given but its presence can allow for compositionality within the network and/or lead to greater extrapolative capability.

#### Tensor Representation

The default Simulator in pm4py is a little slow.
A net with 100+ places takes on the order of a minute to emit an EventLog on the order of thousands of elements.

See [[Simulator]] for more on how to improve this.

The **StructureNet** wrapper therefore exposes a `to_tensor()` function which converts it to a suitable tensor representation in a shape the [[Simulator]] expects.